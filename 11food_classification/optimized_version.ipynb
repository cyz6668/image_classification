{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=\"training_label.txt\"\n",
    "with open(tf) as f:\n",
    "    tfl=f.readlines()\n",
    "#print(tfl)\n",
    "outlist=[]\n",
    "for i in tfl:\n",
    "    outlist.append(i[:-1])\n",
    "# print(outlist,'/n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  label\n",
      "0       0_0.jpg      0\n",
      "1       0_1.jpg      0\n",
      "2      0_10.jpg      0\n",
      "3     0_100.jpg      0\n",
      "4     0_101.jpg      0\n",
      "...         ...    ...\n",
      "9861  9_995.jpg      9\n",
      "9862  9_996.jpg      9\n",
      "9863  9_997.jpg      9\n",
      "9864  9_998.jpg      9\n",
      "9865  9_999.jpg      9\n",
      "\n",
      "[9866 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#读取txt文本\n",
    "df =  pd.read_table(tf,sep='\\t',names=['name','label'])\n",
    "print(df)\n",
    "#然后选定label列下的数据，进行绘图\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小： 9866\n",
      "length of label is  11\n",
      "Processing label  : 0\n",
      "Num of the label is :  994\n",
      "Processing label  : 1\n",
      "Num of the label is :  429\n",
      "Processing label  : 2\n",
      "Num of the label is :  1500\n",
      "Processing label  : 3\n",
      "Num of the label is :  986\n",
      "Processing label  : 4\n",
      "Num of the label is :  848\n",
      "Processing label  : 5\n",
      "Num of the label is :  1325\n",
      "Processing label  : 6\n",
      "Num of the label is :  440\n",
      "Processing label  : 7\n",
      "Num of the label is :  280\n",
      "Processing label  : 8\n",
      "Num of the label is :  855\n",
      "Processing label  : 9\n",
      "Num of the label is :  1500\n",
      "Processing label  : 10\n",
      "Num of the label is :  709\n",
      "shuffle后数据集大小： 16500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "def labelShuffling(dataFrame, groupByName='label'):\n",
    "    groupDataFrame = dataFrame.groupby(by=[groupByName])\n",
    "    labels = groupDataFrame.size()\n",
    "    print(\"length of label is \", len(labels))\n",
    "    maxNum = max(labels)\n",
    "    lst = pd.DataFrame()\n",
    "    for i in range(len(labels)):\n",
    "        print(\"Processing label  :\", i)\n",
    "        tmpGroupBy = groupDataFrame.get_group(i)\n",
    "        createdShuffleLabels = np.random.permutation(np.array(range(maxNum))) % labels[i]  # 随机排列组合\n",
    "        print(\"Num of the label is : \", labels[i])\n",
    "        lst=lst.append(tmpGroupBy.iloc[createdShuffleLabels], ignore_index=True)\n",
    "        # print(\"Done\")\n",
    "    # lst.to_csv('test1.csv', index=False)\n",
    "    return lst\n",
    "\n",
    "all_size = len(df)\n",
    "print(\"训练集大小：\", all_size)\n",
    "\n",
    "# train_image_list = df\n",
    "\n",
    "df1 = labelShuffling(df)\n",
    "df1 = shuffle(df1)\n",
    "print(\"shuffle后数据集大小：\", len(df1))\n",
    "\n",
    "# train_image_path_list = df1['name'].values\n",
    "# label_list = df1['label'].values\n",
    "# label_list = torch.to_tensor(label_list, dtype='int64')\n",
    "# train_label_list = torch.nn.functional.one_hot(label_list, num_classes=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'training/'\n",
    "f_test=open('training_label1.txt','a')\n",
    "n=len(df1)\n",
    "#写入txt中\n",
    "\n",
    "for _,_,file in os.walk(file_path):\n",
    "    for f in file:\n",
    "        tmp=f.split('_')[0]\n",
    "        f_test.write(f+'\\t'+tmp+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "class Mydataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,label_file,picture_dir,transform=None):\n",
    "        \n",
    "        # self.label=pd.read_table(label_file,sep='\\t',names=['name','label'])\n",
    "        self.label=label_file\n",
    "        self.image_dir=picture_dir\n",
    "        self.transform=transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx=idx.tolist()\n",
    "        img_name=os.path.join(self.image_dir,self.label.iloc[idx,0])\n",
    "        # image=io.imread(img_name)\n",
    "        # image=cv2.imread(img_name)\n",
    "        image=Image.open(img_name).convert(\"RGB\")\n",
    "        # image = Image.open(img_name).convert('RGB')\n",
    "        image = np.array(image).astype('float32')\n",
    "        image = transform.resize(image,(100,100))\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        # print(type(image))\n",
    "        label=self.label.iloc[idx,1]\n",
    "        sample = {'image':image,'label':label}\n",
    "        if self.transform:\n",
    "            sample=self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_optimized = Mydataset(df1,'training')\n",
    "trainloader_optimized = torch.utils.data.DataLoader(train_dataset_optimized, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "0\n",
      "tensor([6, 3, 5, 0])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(trainloader_optimized, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['image'],data['label']\n",
    "        print(type(inputs))\n",
    "        print(i)\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (conv0): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm_0): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (_batch_norm_1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(50, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4050, out_features=218, bias=True)\n",
      "  (fc2): Linear(in_features=218, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.conv0=nn.Conv2d(3,20,5,padding=0)\n",
    "        self.pool0=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self._batch_norm_0 = nn.BatchNorm2d(num_features=20)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(20,50,kernel_size=5,padding=0)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self._batch_norm_1= nn.BatchNorm2d(num_features=50)\n",
    "\n",
    "        self.conv2=nn.Conv2d(50,50,kernel_size=5,padding=0)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.fc1=nn.Linear(in_features=4050,out_features=218)\n",
    "        self.fc2=nn.Linear(in_features=218,out_features=100)\n",
    "        self.fc3=nn.Linear(in_features=100,out_features=11)\n",
    "    def forward(self,input):\n",
    "        input=input.reshape(-1,3,100,100)\n",
    "        x = self.conv0(input)  #数据输入卷积层\n",
    "        x = F.relu(x)  # 激活层\n",
    "        x = self.pool0(x)  # 池化层\n",
    "        x = self._batch_norm_0(x)  # 归一层\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self._batch_norm_1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.fc1(x)  # 线性层\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        y = F.softmax(x)  # 分类器\n",
    "        return y\n",
    "\n",
    "\n",
    "net = MyNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_52040/1702851010.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y = F.softmax(x)  # 分类器\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 2.287\n",
      "[1,  2000] loss: 2.288\n",
      "[1,  3000] loss: 2.284\n",
      "[1,  4000] loss: 2.276\n",
      "[2,  1000] loss: 2.270\n",
      "[2,  2000] loss: 2.264\n",
      "[2,  3000] loss: 2.260\n",
      "[2,  4000] loss: 2.248\n",
      "[3,  1000] loss: 2.252\n",
      "[3,  2000] loss: 2.237\n",
      "[3,  3000] loss: 2.241\n",
      "[3,  4000] loss: 2.230\n",
      "[4,  1000] loss: 2.221\n",
      "[4,  2000] loss: 2.214\n",
      "[4,  3000] loss: 2.221\n",
      "[4,  4000] loss: 2.207\n",
      "[5,  1000] loss: 2.213\n",
      "[5,  2000] loss: 2.193\n",
      "[5,  3000] loss: 2.196\n",
      "[5,  4000] loss: 2.188\n",
      "[6,  1000] loss: 2.190\n",
      "[6,  2000] loss: 2.171\n",
      "[6,  3000] loss: 2.183\n",
      "[6,  4000] loss: 2.173\n",
      "[7,  1000] loss: 2.172\n",
      "[7,  2000] loss: 2.153\n",
      "[7,  3000] loss: 2.155\n",
      "[7,  4000] loss: 2.150\n",
      "[8,  1000] loss: 2.140\n",
      "[8,  2000] loss: 2.130\n",
      "[8,  3000] loss: 2.135\n",
      "[8,  4000] loss: 2.128\n",
      "[9,  1000] loss: 2.126\n",
      "[9,  2000] loss: 2.114\n",
      "[9,  3000] loss: 2.107\n",
      "[9,  4000] loss: 2.108\n",
      "[10,  1000] loss: 2.104\n",
      "[10,  2000] loss: 2.092\n",
      "[10,  3000] loss: 2.087\n",
      "[10,  4000] loss: 2.092\n",
      "[11,  1000] loss: 2.085\n",
      "[11,  2000] loss: 2.071\n",
      "[11,  3000] loss: 2.069\n",
      "[11,  4000] loss: 2.075\n",
      "[12,  1000] loss: 2.069\n",
      "[12,  2000] loss: 2.055\n",
      "[12,  3000] loss: 2.049\n",
      "[12,  4000] loss: 2.051\n",
      "[13,  1000] loss: 2.044\n",
      "[13,  2000] loss: 2.040\n",
      "[13,  3000] loss: 2.032\n",
      "[13,  4000] loss: 2.031\n",
      "[14,  1000] loss: 2.024\n",
      "[14,  2000] loss: 2.020\n",
      "[14,  3000] loss: 2.018\n",
      "[14,  4000] loss: 2.020\n",
      "[15,  1000] loss: 2.007\n",
      "[15,  2000] loss: 2.003\n",
      "[15,  3000] loss: 2.007\n",
      "[15,  4000] loss: 1.998\n",
      "[16,  1000] loss: 1.991\n",
      "[16,  2000] loss: 1.986\n",
      "[16,  3000] loss: 1.992\n",
      "[16,  4000] loss: 1.994\n",
      "[17,  1000] loss: 1.975\n",
      "[17,  2000] loss: 1.965\n",
      "[17,  3000] loss: 1.976\n",
      "[17,  4000] loss: 1.973\n",
      "[18,  1000] loss: 1.955\n",
      "[18,  2000] loss: 1.958\n",
      "[18,  3000] loss: 1.966\n",
      "[18,  4000] loss: 1.962\n",
      "[19,  1000] loss: 1.947\n",
      "[19,  2000] loss: 1.948\n",
      "[19,  3000] loss: 1.956\n",
      "[19,  4000] loss: 1.950\n",
      "[20,  1000] loss: 1.930\n",
      "[20,  2000] loss: 1.932\n",
      "[20,  3000] loss: 1.937\n",
      "[20,  4000] loss: 1.942\n",
      "[21,  1000] loss: 1.919\n",
      "[21,  2000] loss: 1.929\n",
      "[21,  3000] loss: 1.931\n",
      "[21,  4000] loss: 1.926\n",
      "[22,  1000] loss: 1.911\n",
      "[22,  2000] loss: 1.914\n",
      "[22,  3000] loss: 1.922\n",
      "[22,  4000] loss: 1.916\n",
      "[23,  1000] loss: 1.902\n",
      "[23,  2000] loss: 1.917\n",
      "[23,  3000] loss: 1.917\n",
      "[23,  4000] loss: 1.911\n",
      "[24,  1000] loss: 1.886\n",
      "[24,  2000] loss: 1.894\n",
      "[24,  3000] loss: 1.910\n",
      "[24,  4000] loss: 1.901\n",
      "[25,  1000] loss: 1.876\n",
      "[25,  2000] loss: 1.887\n",
      "[25,  3000] loss: 1.892\n",
      "[25,  4000] loss: 1.886\n",
      "[26,  1000] loss: 1.871\n",
      "[26,  2000] loss: 1.882\n",
      "[26,  3000] loss: 1.883\n",
      "[26,  4000] loss: 1.878\n",
      "[27,  1000] loss: 1.856\n",
      "[27,  2000] loss: 1.869\n",
      "[27,  3000] loss: 1.880\n",
      "[27,  4000] loss: 1.871\n",
      "[28,  1000] loss: 1.848\n",
      "[28,  2000] loss: 1.862\n",
      "[28,  3000] loss: 1.870\n",
      "[28,  4000] loss: 1.858\n",
      "[29,  1000] loss: 1.839\n",
      "[29,  2000] loss: 1.854\n",
      "[29,  3000] loss: 1.860\n",
      "[29,  4000] loss: 1.856\n",
      "[30,  1000] loss: 1.832\n",
      "[30,  2000] loss: 1.844\n",
      "[30,  3000] loss: 1.855\n",
      "[30,  4000] loss: 1.846\n",
      "[31,  1000] loss: 1.827\n",
      "[31,  2000] loss: 1.831\n",
      "[31,  3000] loss: 1.841\n",
      "[31,  4000] loss: 1.845\n",
      "[32,  1000] loss: 1.821\n",
      "[32,  2000] loss: 1.826\n",
      "[32,  3000] loss: 1.831\n",
      "[32,  4000] loss: 1.837\n",
      "[33,  1000] loss: 1.817\n",
      "[33,  2000] loss: 1.824\n",
      "[33,  3000] loss: 1.826\n",
      "[33,  4000] loss: 1.833\n",
      "[34,  1000] loss: 1.812\n",
      "[34,  2000] loss: 1.817\n",
      "[34,  3000] loss: 1.819\n",
      "[34,  4000] loss: 1.821\n",
      "[35,  1000] loss: 1.798\n",
      "[35,  2000] loss: 1.818\n",
      "[35,  3000] loss: 1.818\n",
      "[35,  4000] loss: 1.825\n",
      "[36,  1000] loss: 1.795\n",
      "[36,  2000] loss: 1.808\n",
      "[36,  3000] loss: 1.812\n",
      "[36,  4000] loss: 1.813\n",
      "[37,  1000] loss: 1.788\n",
      "[37,  2000] loss: 1.798\n",
      "[37,  3000] loss: 1.806\n",
      "[37,  4000] loss: 1.810\n",
      "[38,  1000] loss: 1.791\n",
      "[38,  2000] loss: 1.799\n",
      "[38,  3000] loss: 1.801\n",
      "[38,  4000] loss: 1.800\n",
      "[39,  1000] loss: 1.781\n",
      "[39,  2000] loss: 1.790\n",
      "[39,  3000] loss: 1.799\n",
      "[39,  4000] loss: 1.796\n",
      "[40,  1000] loss: 1.771\n",
      "[40,  2000] loss: 1.788\n",
      "[40,  3000] loss: 1.800\n",
      "[40,  4000] loss: 1.789\n",
      "[41,  1000] loss: 1.772\n",
      "[41,  2000] loss: 1.785\n",
      "[41,  3000] loss: 1.795\n",
      "[41,  4000] loss: 1.792\n",
      "[42,  1000] loss: 1.770\n",
      "[42,  2000] loss: 1.788\n",
      "[42,  3000] loss: 1.790\n",
      "[42,  4000] loss: 1.783\n",
      "[43,  1000] loss: 1.763\n",
      "[43,  2000] loss: 1.774\n",
      "[43,  3000] loss: 1.783\n",
      "[43,  4000] loss: 1.779\n",
      "[44,  1000] loss: 1.762\n",
      "[44,  2000] loss: 1.774\n",
      "[44,  3000] loss: 1.781\n",
      "[44,  4000] loss: 1.779\n",
      "[45,  1000] loss: 1.762\n",
      "[45,  2000] loss: 1.769\n",
      "[45,  3000] loss: 1.782\n",
      "[45,  4000] loss: 1.775\n",
      "[46,  1000] loss: 1.752\n",
      "[46,  2000] loss: 1.765\n",
      "[46,  3000] loss: 1.783\n",
      "[46,  4000] loss: 1.771\n",
      "[47,  1000] loss: 1.754\n",
      "[47,  2000] loss: 1.764\n",
      "[47,  3000] loss: 1.773\n",
      "[47,  4000] loss: 1.768\n",
      "[48,  1000] loss: 1.748\n",
      "[48,  2000] loss: 1.759\n",
      "[48,  3000] loss: 1.770\n",
      "[48,  4000] loss: 1.767\n",
      "[49,  1000] loss: 1.749\n",
      "[49,  2000] loss: 1.759\n",
      "[49,  3000] loss: 1.769\n",
      "[49,  4000] loss: 1.760\n",
      "[50,  1000] loss: 1.747\n",
      "[50,  2000] loss: 1.762\n",
      "[50,  3000] loss: 1.763\n",
      "[50,  4000] loss: 1.759\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader_optimized, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['image'],data['label']\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './tmp_net2.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_52040/1702851010.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y = F.softmax(x)  # 分类器\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=Image.open(\"1.png\").convert(\"RGB\")\n",
    "image = np.array(img).astype('float32')\n",
    "image = transform.resize(image,(100,100))\n",
    "print(image.size)\n",
    "image = torch.tensor(image, dtype=torch.float32)\n",
    "outputs=net(image)\n",
    "_,predicted = torch.max(outputs,1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_table(\"testing_label.txt\",sep='\\t',names=['name','label'])\n",
    "test_dataset = Mydataset(label_file=df_test,picture_dir='validation/')\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "dataiter = iter(testloader)\n",
    "tmp=dataiter.next()\n",
    "images, labels =tmp['image'],tmp['label']\n",
    "classes=['Bread', 'Dairy product', 'Dessert', 'Egg', 'Fried food', 'Meat', 'Noodles/Pasta', 'Rice', 'Seafood', 'Soup','Vegetable/Fruit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_52040/1702851010.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  y = F.softmax(x)  # 分类器\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0\n",
      "3432\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "tmp=dataiter.next()\n",
    "sumnum_2=0\n",
    "sumnum_1=0\n",
    "for i,data in enumerate(testloader):\n",
    "    images,labels = data['image'],data['label']\n",
    "    outputs=net(images)\n",
    "    _,predicted = torch.max(outputs,1)\n",
    "    mask=predicted==labels\n",
    "    sumnum=sum(mask)\n",
    "    sumnum_1+=sumnum_1\n",
    "    sumnum_2=sumnum_2+4\n",
    "    if i==1000:break\n",
    "print(sumnum_1/sumnum_2)\n",
    "print(sumnum_1)\n",
    "print(sumnum_2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a6378035587bb97055001603ea9d85a2aa377cc6252a50ffca4355a71bc8b90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
